{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "assignment-title"
      },
      "source": [
        "# Assignment 4: Denoising Diffusion Probabilistic Models (DDPMs) in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "introduction"
      },
      "source": [
        "## Introduction\n",
        "Denoising Diffusion Probabilistic Models (DDPMs) are a class of generative models that have shown remarkable success in synthesizing high-quality images. They work by iteratively denoising a noisy input to gradually transform it into a sample from the data distribution. This assignment will guide you through implementing a basic DDPM in PyTorch to generate images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "objective"
      },
      "source": [
        "## Objective\n",
        "The goal of this assignment is to implement a Denoising Diffusion Probabilistic Model (DDPM) using PyTorch. You will train the model on the MNIST dataset to generate new handwritten digit images. The assignment will cover data preparation, model architecture design, defining the diffusion process, and setting up the training loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imports-task"
      },
      "source": [
        "## Setup and Imports\n",
        "Begin by importing the necessary libraries. You will primarily use `torch`, `torch.nn`, `torchvision`, and `matplotlib`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "required-imports"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from math import sqrt, log\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data-prep-task"
      },
      "source": [
        "## 1. Data Preparation\n",
        "Load the MNIST dataset and apply necessary transformations. The images should be resized and normalized to a range of [-1, 1]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data-prep-code-cell"
      },
      "outputs": [],
      "source": [
        "# Task: Implement data loading and preprocessing for MNIST\n",
        "# - Set up device (CUDA if available, else CPU)\n",
        "# - Define transformations: Resize to 32x32, convert to Tensor, normalize to [-1, 1]\n",
        "# - Load MNIST training dataset\n",
        "# - Create a DataLoader with appropriate batch size and shuffling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model-architecture-task"
      },
      "source": [
        "## 2. Model Architecture (U-Net)\n",
        "Implement a U-Net architecture to predict the noise added to images. The U-Net should incorporate sinusoidal time embeddings to inform the network about the current diffusion timestep."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "time-embedding-task"
      },
      "source": [
        "### 2.1. Sinusoidal Time Embedding\n",
        "Implement a `SinusoidalTimeEmbedding` class that generates embeddings for the diffusion timestep `t`. This embedding helps the U-Net understand which timestep it is currently processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "time-embedding-code-cell"
      },
      "outputs": [],
      "source": [
        "class SinusoidalTimeEmbedding(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, t):\n",
        "        # TODO: Implement sinusoidal time embedding as described in diffusion models papers.\n",
        "        # The embedding should have 'self.dim' dimensions.\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unet-block-task"
      },
      "source": [
        "### 2.2. U-Net Block\n",
        "Define a basic U-Net building block. This block should consist of convolutional layers, group normalization, and activation functions (e.g., SiLU). Crucially, it should incorporate the time embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unet-block-code-cell"
      },
      "outputs": [],
      "source": [
        "class UNetBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, time_emb_dim):\n",
        "        super().__init__()\n",
        "        # TODO: Implement the U-Net block. It should take time_emb_dim as input\n",
        "        # and integrate it into the block's processing (e.g., via a linear layer).\n",
        "        pass\n",
        "\n",
        "    def forward(self, x, t_emb):\n",
        "        # TODO: Implement the forward pass for the U-Net block, including time embedding integration.\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "full-unet-task"
      },
      "source": [
        "### 2.3. Full U-Net Model\n",
        "Assemble the U-Net model using the `UNetBlock` and `SinusoidalTimeEmbedding`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "full-unet-code-cell"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=1, base_channels=64, time_emb_dim=128):\n",
        "        super().__init__()\n",
        "        # TODO: Initialize the SinusoidalTimeEmbedding and U-Net blocks (downsampling and upsampling paths).\n",
        "        # Include pooling layers for downsampling and upsampling layers for upsampling.\n",
        "        pass\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        # TODO: Implement the forward pass, applying time embeddings and passing through U-Net blocks.\n",
        "        # Ensure proper skip connections are implemented if desired (though not explicitly shown in solution, common for UNet).\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diffusion-functions-task"
      },
      "source": [
        "## 3. Diffusion Process Functions\n",
        "Implement the helper functions required for the diffusion process: beta schedule and adding noise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beta-schedule-task"
      },
      "source": [
        "### 3.1. Beta Schedule\n",
        "Define a function that generates the `betas` and `alphas_cumprod` (cumulative product of 1-betas) for the diffusion process. These values are crucial for the forward and reverse diffusion steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beta-schedule-code-cell"
      },
      "outputs": [],
      "source": [
        "def get_beta_schedule(T):\n",
        "    # TODO: Implement a linear beta schedule and calculate alphas and alphas_cumprod.\n",
        "    # 'T' is the total number of diffusion steps.\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "add-noise-task"
      },
      "source": [
        "### 3.2. Add Noise Function\n",
        "Implement a function `add_noise` that applies noise to an image `x_0` at a given timestep `t`, based on the pre-computed beta schedule."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "add-noise-code-cell"
      },
      "outputs": [],
      "source": [
        "def add_noise(x_0, noise, t, schedule):\n",
        "    # TODO: Implement the forward diffusion process (q(x_t | x_0)).\n",
        "    # This function should add noise to x_0 according to the schedule at timestep t.\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training-task"
      },
      "source": [
        "## 4. Training\n",
        "Set up the training loop for the DDPM. The model will be trained to predict the noise added to the image at various timesteps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train-step-task"
      },
      "source": [
        "### 4.1. Training Step\n",
        "Implement a single `train_step` function that performs one optimization step: sampling a random timestep, adding noise, predicting noise with the U-Net, calculating MSE loss, and updating model parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train-step-code-cell"
      },
      "outputs": [],
      "source": [
        "def train_step(model, x_0, optimizer, schedule, T):\n",
        "    # TODO: Implement a single training step for the diffusion model.\n",
        "    # - Sample random timesteps 't'.\n",
        "    # - Generate noise and add it to 'x_0' using the 'add_noise' function.\n",
        "    # - Predict the noise using the 'model' (U-Net).\n",
        "    # - Calculate the MSE loss between predicted noise and true noise.\n",
        "    # - Perform backpropagation and optimizer step.\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train-loop-task"
      },
      "source": [
        "### 4.2. Training Loop\n",
        "Create the main training function `train_diffusion_on_mnist` that iterates over epochs and data loaders, calling `train_step` for each batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train-loop-code-cell"
      },
      "outputs": [],
      "source": [
        "def train_diffusion_on_mnist(epochs=50, T=500):\n",
        "    # TODO: Initialize the U-Net model and optimizer.\n",
        "    # TODO: Get the beta schedule.\n",
        "    # TODO: Implement the main training loop, iterating over epochs and data batches.\n",
        "    # Call 'train_step' for each batch and print the average loss per epoch.\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sampling-task"
      },
      "source": [
        "## 5. Sampling and Evaluation\n",
        "After training, implement the sampling (reverse diffusion) process to generate new images from pure noise. Visualize the generated images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reverse-diffusion-task"
      },
      "source": [
        "### 5.1. Reverse Diffusion (Sampling)\n",
        "Implement a function to perform the reverse diffusion process. Starting from random noise, iteratively denoise the image using your trained U-Net."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sampling-code-cell"
      },
      "outputs": [],
      "source": [
        "def sample_images(model, schedule, T, num_samples=16):\n",
        "    # TODO: Implement the reverse diffusion (sampling) process.\n",
        "    # Start with pure noise and iteratively apply the denoising step using the trained model.\n",
        "    # You will need to use the beta schedule and the predicted noise to estimate x_{t-1} from x_t.\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualization-task"
      },
      "source": [
        "### 5.2. Visualization\n",
        "Visualize some of the noisy examples from the forward process and generated images from the reverse process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "visualization-code-cell"
      },
      "outputs": [],
      "source": [
        "def show_noisy_example(model, schedule, T=1000):\n",
        "    # TODO: Pick an image from the dataset and a random timestep 't'.\n",
        "    # Add noise to the image at timestep 't' and display both the original and noisy images.\n",
        "    pass\n",
        "\n",
        "def plot_generated_images(images):\n",
        "    # TODO: Plot a grid of generated images.\n",
        "    pass\n",
        "\n",
        "# TODO: Call your training and sampling functions, then visualize results.\n",
        "# model, schedule = train_diffusion_on_mnist()\n",
        "# show_noisy_example(model, schedule)\n",
        "# generated_images = sample_images(model, schedule, T=500)\n",
        "# plot_generated_images(generated_images)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
